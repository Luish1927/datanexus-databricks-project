{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0601c100-f2f8-4a5f-bbf8-323b02d2b092",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2dfcffa-862f-4a35-9c1e-1515c74a4f29",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configurações de Performance"
    }
   },
   "outputs": [],
   "source": [
    "# configs de performance\n",
    "\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e0e7c5d-794f-45a0-aece-fb78736481e3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PATHS"
    }
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "path_silver = \"abfss://silver@storagedatanexus.dfs.core.windows.net/\"\n",
    "target_table = \"gold.rst_exp_imp_pais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59341a6a-92e1-4661-9490-658dd42ee347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_export = spark.read.table(\"silver_comercio_ext_estatisticas.tb_exportacoes\") \\\n",
    "    .select(\n",
    "        \"CO_ANO\", \n",
    "        \"CO_MES\", \n",
    "        \"CO_PAIS\",\n",
    "        \"CO_NCM\", \n",
    "        \"VL_FOB\", \n",
    "    )\n",
    "\n",
    "df_import = spark.read.table(\"silver_comercio_ext_estatisticas.tb_importacoes\") \\\n",
    "    .select(\n",
    "        \"CO_ANO\", \n",
    "        \"CO_MES\", \n",
    "        \"CO_PAIS\",\n",
    "        \"CO_NCM\", \n",
    "        \"VL_FOB\", \n",
    "    )\n",
    "    \n",
    "df_dim_pais = spark.read.table(\"silver_comercio_ext_auxiliares.tb_auxiliar_paises\") \\\n",
    "    .select(\n",
    "        \"CO_PAIS\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2579753-865a-4f24-944f-84d7f17d0301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dim_isic_ncm = spark.read.table(\"silver_comercio_ext_indices.tb_nomenclatura_mercosul\") \\\n",
    "    .select(\n",
    "        \"CO_NCM\", \n",
    "        \"CO_ISIC_CLASSE\",\n",
    "    )\n",
    "\n",
    "df_dim_isic = spark.read.table(\"silver_comercio_ext_indices.tb_referencia_ncm_isic\") \\\n",
    "    .select(\n",
    "        \"CO_ISIC_CLASSE\",\n",
    "        \"CO_ISIC_DIVISAO\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a23e0b77-7c58-4a07-b3bf-2c942a05367f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# =========================================================\n",
    "# Agregação exportações\n",
    "# =========================================================\n",
    "exp_mensal = (\n",
    "    df_export\n",
    "    .groupBy(\"CO_ANO\", \"CO_MES\", \"CO_PAIS\", \"CO_NCM\")\n",
    "    .agg(F.sum(\"VL_FOB\").alias(\"total_exportado\"))\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# Agregação importações\n",
    "# =========================================================\n",
    "imp_mensal = (\n",
    "    df_import\n",
    "    .groupBy(\"CO_ANO\", \"CO_MES\", \"CO_PAIS\", \"CO_NCM\")\n",
    "    .agg(F.sum(\"VL_FOB\").alias(\"total_importado\"))\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# Union export + import (FULL)\n",
    "# =========================================================\n",
    "fato_mensal = (\n",
    "    exp_mensal.alias(\"e\")\n",
    "    .join(\n",
    "        imp_mensal.alias(\"i\"),\n",
    "        [\"CO_ANO\", \"CO_MES\", \"CO_PAIS\", \"CO_NCM\"],\n",
    "        \"full\"\n",
    "    )\n",
    "    .select(\n",
    "        F.coalesce(F.col(\"e.CO_ANO\"),  F.col(\"i.CO_ANO\")).cast(\"int\").alias(\"ano_operacao\"),\n",
    "        F.coalesce(F.col(\"e.CO_MES\"),  F.col(\"i.CO_MES\")).cast(\"int\").alias(\"mes_operacao\"),\n",
    "        F.coalesce(F.col(\"e.CO_PAIS\"), F.col(\"i.CO_PAIS\")).alias(\"CO_PAIS\"),\n",
    "        F.coalesce(F.col(\"e.CO_NCM\"),  F.col(\"i.CO_NCM\")).alias(\"CO_NCM\"),\n",
    "        F.coalesce(F.col(\"e.total_exportado\"), F.lit(0)).alias(\"total_exportado\"),\n",
    "        F.coalesce(F.col(\"i.total_importado\"), F.lit(0)).alias(\"total_importado\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# Dimensões\n",
    "# =========================================================\n",
    "dim_pais = df_dim_pais.dropDuplicates([\"CO_PAIS\"])\n",
    "dim_isic_ncm = df_dim_isic_ncm.dropDuplicates([\"CO_NCM\"])\n",
    "dim_isic = df_dim_isic.dropDuplicates([\"CO_ISIC_CLASSE\"])\n",
    "\n",
    "# =========================================================\n",
    "# Fato final enriquecido\n",
    "# =========================================================\n",
    "rst_exp_imp_pais = (\n",
    "    fato_mensal\n",
    "    .join(dim_pais, on=\"CO_PAIS\", how=\"left\")\n",
    "    .join(dim_isic_ncm, on=\"CO_NCM\", how=\"left\")\n",
    "    .join(dim_isic, on=\"CO_ISIC_CLASSE\", how=\"left\")\n",
    "    .withColumn(\n",
    "        \"ano_mes\",\n",
    "        F.concat_ws(\n",
    "            \"-\",\n",
    "            F.col(\"ano_operacao\"),\n",
    "            F.lpad(F.col(\"mes_operacao\").cast(\"string\"), 2, \"0\")\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"saldo\",\n",
    "        (\n",
    "            F.col(\"total_exportado\").cast(\"float\")\n",
    "            - F.col(\"total_importado\").cast(\"float\")\n",
    "        )\n",
    "    )\n",
    "    .select(\n",
    "        \"ano_operacao\",\n",
    "        \"mes_operacao\",\n",
    "        \"ano_mes\",\n",
    "\n",
    "        F.col(\"CO_PAIS\").cast(\"string\").alias(\"cod_pais\"),\n",
    "        F.col(\"CO_NCM\").cast(\"string\").alias(\"cod_ncm\"),\n",
    "        F.col(\"CO_ISIC_DIVISAO\").cast(\"string\").alias(\"cod_div_isic\"),\n",
    "        F.col(\"CO_ISIC_CLASSE\").cast(\"string\").alias(\"cod_isic\"),\n",
    "\n",
    "        F.col(\"total_exportado\").cast(\"float\"),\n",
    "        F.col(\"total_importado\").cast(\"float\"),\n",
    "        F.col(\"saldo\").cast(\"float\")\n",
    "    )\n",
    "    .orderBy(\n",
    "        \"ano_operacao\",\n",
    "        \"mes_operacao\",\n",
    "        \"cod_pais\",\n",
    "        \"cod_isic\",\n",
    "        \"cod_ncm\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc62662a-ea35-4ab6-ad87-ef9218acb9ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(rst_exp_imp_pais.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb4c24a3-5ada-4832-a21e-4b43784ff583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rst_exp_imp_pais.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"ano_operacao\", \"mes_operacao\") \\\n",
    "    .saveAsTable(target_table)\n",
    "\n",
    "spark.sql(f\"OPTIMIZE gold.rst_exp_imp_pais ZORDER BY (cod_pais, cod_isic)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rst_exp_imp_pais",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
